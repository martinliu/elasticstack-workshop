---
title: "使用 Kibana 分析开源项目的KPI"
date: 2017-10-17T15:26:15Z
draft: false
weight: 23
---

开源项目的火热程度取决于技术创新+行业趋势，很多风口浪尖的开源项目确实非常吸引人。GitHub中的项目好不好，是不是光数星星就够了？该如何洞察一个项目的社区参与程度？如何判断核心开发团队的工作效能？为了回答这些深度的问题，还需要对其进行深度的分析。本教程教你使用 Elastic Stack 构建 GitHub 上开源项目的关键分析指标看板，在 Kibana 中详细分析项目的各个关键维度。 


{{< panel title="学习目标" >}}
1）使用  zip / tar.gz 软件包在本地搭建 Elastic Stack 开发环境；2） 使用 Filebeat 的 HTTP JSON inputedit 插件从 GitHub API 下载分析数据；3）在 Kibana 中查询和分析文档数据，为图形化展示做好准备；4）掌握 Kibana 数据分析展示看板的基本操作。{{< /panel >}}


## 准备工作

1. 在浏览器中打开网址 https://www.elastic.co/downloads/past-releases#elasticsearch ； 下载 elasticsearch-7.17.0-darwin-aarch64.tar.gz 、kibana-7.17.0-darwin-aarch64.tar.gz 、 filebeat-7.17.0-darwin-x86_64.tar.gz 软件包。请自行选择正确的平台，以上 darwin-aarch64 软件包适用于 moacOS M1 平台；而 darwin-x86_64 软件包适用于 macOS Intel 平台。本视频演示的是下载 Windows 平台的 zip软件包
2. 在 GitHub 中创建 personal token，用于提升访问 GitHub Api 下载的数据条数限制

![github personal access token](/images/personal_access_token.png)

保存这个界面中的类似于这样的个人访问令牌 `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`


## 启动开发环境

**启动 Elasticsearch 服务器**：下面是在 macOS M1 平台上解压缩 Elasticsearch 软件包，进入解压后的软件包的目录，使用其可执行文件启动服务。

```
tar zxvf elasticsearch-7.17.0-darwin-aarch64.tar.gz
cd elasticsearch-7.17.0
bin/elasticsearch -Enode.name=mac-m1
```

如果是在 Windows 平台上，使用系统带的解压缩软件将 zip 软件包解压。


**启动 Kibana 服务器**：

```
tar zxvf kibana-7.17.0-darwin-aarch64.tar.gz
cd kibana-7.17.0-darwin-aarch64
bin/kibana
```

这样就启动了 Kibana 服务器，进入解压后的软件包的目录，使用其可执行文件启动服务。它默认会连接上一步所启动的 Elasticsearch 服务器，在这个开发环境中，默认没有启用用户名和密码认证。

**准备 Filebeat 的运行环境**：解压缩 Filebeat 软件包，进入解压后的目录，备份默认的 `filebeat.yml` 重命名为 `filebeat.yml.bk`。

```
tar zxvf filebeat-7.17.0-darwin-x86_64.tar.gz
cd filebeat-7.17.0-darwin-x86_64
mv filebeat.yml filebeat.yml.bk
```

**初始化 Kibana 的配置**。在浏览器中输入 `http://localhost:5601` ，在登陆了 Kibana 之后，点击左上交的图标，打开左侧隐藏菜单，找到 Stack Management --> Kibana --> Advanced Setting 页面中的这两个选项。

* 打开 “Dark mode” 选项，**打开暗黑模式界面**。

![kibana-dark-mode](/images/kibana-dark-mode.png)

* 设置 “Document Explorer or classic view” 选项。**关闭默认的 classic 经典视图模式**。

![doc-explorer](/images/doc-explorer.png)

{{< panel status="success" title="自查点" >}}
已经成功的将 Elasticsearch 和 Kibana 在本机上，启动并运行正常。可以在浏览器中访问 Kibana 的界面。浏览若干重要的功能界面：Discover、Dashboard、DevTools、Stack Management等。
{{< /panel >}}


## 下载参考配置文件

为了降低学习Kibana数据看板的搭建门槛，请下载准备好的示例文件。

{{< button status="success" icon="fas fa-cloud-download-alt" url="https://github.com/martinliu/sdp-dashboard/archive/refs/heads/main.zip" >}}下载{{< /button >}}

解压以上的zip文件后，其中的三个文件会被使用到：

1. filebeat.yml ： 完整的 Filebeat 配置参数模版。用它替换 Filebeat 的默认配置文件。本示例配置文件分析的是 OpenShift 的 origin 项目，是一个非常火热的项目。需要几天时间才能完整下载所有数据，也可以根据需要将其替换。
2. add_gh_fields.json ： GitHub项目属性扩展字段定义。将其放入 Filebeat 程序文件夹的目录中。
3. export-v1.0.ndjson ： Kibana 可视化数据分析看板模版。将其倒入到新安装的 Kibana 中。

以上三个文件适用于任何操作系统，

## 使用 Filebeat 同步数据

Filebeat 包含多种数据摄入模块：

* AWS CloudWatch
* AWS S3
* Azure Event Hub
* Cloud Foundry
* Container
* filestream
* GCP Pub/Sub
* HTTP Endpoint
* HTTP JSON
* journald
* Kafka
* Log
* MQTT
* NetFlow
* Office 365 Management Activity API
* Redis
* Stdin
* Syslog
* TCP
* UDP

以上模块已经可以覆盖不少的数据源，灵活使用这些模块，就可以将 Filebeat 当作一个 mini 版的 Logstash 使用，当然 Logstash 包含了更丰富的摄入模块和数据处理能力。

### 获取开源项目概要信息

本教程提供的示例配置文件，采集的是 OpenShift 的项目数据，你可以替换为你的目标分析项目。将下载示例配置文件中的 `add_gh_fields.json` 和 `filebeat.yml` 放入 Filebeat 的目录中 。

使用微软的 Virtual Studio Code 编辑器【或者其他的纯文本编辑器】打开 `filebeat.yml` 示例文件。查看该示例文件，并且**删除掉中间的大部分内容**「**或者注释掉这部分先不用的代码**」，留下剩余的部分做初始化测试。留下的部分如下所示。 并使用上面准备好的 GitHub Personal Access Token 替换配置文件中第21行中对应的参数。

```yml
###################### Filebeat Configuration Example #########################
# ============================== Filebeat inputs ===============================
filebeat.inputs:
# ============================== 建议先获取这一部分的数据  ===============================
# overall, contributors, releases, languages, tags 的数据少且重要，可以手工确认之后在做第二部分

# 获取项目的概要信息 - overall
# GET /repos/{owner}/{repo}
- type: httpjson
  interval: 120m
  config_version: 2
  request.url: https://api.github.com/repos/openshift/origin
  request.method: GET 
  # 在请求中增加个人认证令牌，提高数据获取条数限制
  request.transforms:
    - set:
        target: header.Authorization
        value: 'token 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'
  # 使用数据处理器，修整数据
  processors:
    # 优化分析：增加方便搜索分析的字段  
    - add_fields: 
        fields:
          project: origin
          kpi: overall
    # 解码裸json结果：将 message 字段中的 json 内容解码为多个字段
    - decode_json_fields: 
        fields: ["message"]
        target: "json"

# ======================= Elasticsearch template setting =======================
# 配置索引模版基础属性
setup.template.overwrite: true
setup.template.settings:
  index.number_of_shards: 1
  number_of_replicas: 0
  index.mapping.total_fields.limit: 5000

setup.template.name: "filebeat"
setup.template.pattern: "filebeat-*"
setup.template.fields: "fields.yml"

# 修改部分 json 字段默认的数据类型
setup.template.json.enabled: true
setup.template.json.path: "add_gh_fields.json"
setup.template.json.name: "add_gh_fields"

# 禁用ilm功能
setup.ilm.enabled: false
# ================================== General ===================================
name: github-crawler
# ================================== Outputs ===================================
# ---------------------------- Elasticsearch Output ----------------------------
output.elasticsearch:
  hosts: ["localhost:9200"]
  index: "filebeat-7"
# ================================= Processors =================================
# 删除 Filebeeat 采集到的无关数据，节省存储空间
processors:
 - drop_fields:
     fields: ["ecs", "agent", "input", "host", "message"]    
# ================================== Logging ===================================
logging.level: debug
# ============================= X-Pack Monitoring ==============================
# monitoring.enabled: true     
```
以上配置文件仅使用了必要的参数选项，目的是实现开源项目概要参数信息的抓取，并测试 Filebeat 的可用性(filebeat-7.17.0-darwin-x86_64.tar.gz是可以正常运行在macOS M1平台的)。

不论是 macOS，Windows 还是 Linux ，打开命令行工具，进入 Filebeat 的解压缩目录执行下面的测试。

```sh
➜  filebeat-7.17.0-darwin-x86_64 ./filebeat test output
elasticsearch: http://localhost:9200...
  parse url... OK
  connection...
    parse host... OK
    dns lookup... OK
    addresses: ::1, 127.0.0.1
    dial up... OK
  TLS... WARN secure connection disabled
  talk to server... OK
  version: 7.17.0

```
命令 `./filebeat test output` 的返回结果表明：Filebeat 可以正常连接本机的 Elasticsearch 服务器。在Windows操作系统中，需要将 `filebeat` 可执行文件名换成 `filebeat.exe` ，后面的命令行参数不变。如果 filebeat.yml 配置文件的语法错误，这个命令中会报错。



### GitHub API 的限流和限速

使用 Filebeat 作为客户端访问 GitHub API需要了解的重要信息都在官方文档上：[点这里](https://docs.github.com/en/rest/overview/resources-in-the-rest-api#rate-limiting)；本节内容是必须要理解的内容，必须要在运行 Filebeat 的操作系统上做的测试和操作。

* 认证用户每小时的请求发送配额是 5000 次；对于比较流行的项目而言，issue 或 pull request 任意一类都可以轻易超过这个数值，建议使用 since 参数先拉取近期的数据分析，然后逐步拉取旧数据。
* 企业版用户的配额高一些，每个用户，每小时的配额是 15000 次。
* 未认证用户，每小时限制在60次请求。
* 建议在大概分析了 overall, contributors, releases, languages, tags，issues 和 pull request 等数据的条数后，在逐渐的开始逐项的采集各类数据。
* 可以用加大 page size 参数 【per_page 100是最大】的方式降低需要发出的请求次数。page size 越小，采集的项目数据量越大，越可能碰到被限流的情况。


检查当前用户是否被限流的方法。在命令行里运行这条命令 `curl -u martinliu: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 -I https://api.github.com/users/octocat` ； 这个命令中  `-u martinliu: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` 包含了用户名和个人访问令牌（PAT）。

```sh
➜ curl -u martinliu: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 -I https://api.github.com/users/octocat
HTTP/2 200
server: GitHub.com
date: Thu, 17 Mar 2022 11:01:02 GMT
content-type: application/json; charset=utf-8
content-length: 1335
cache-control: private, max-age=60, s-maxage=60
vary: Accept, Authorization, Cookie, X-GitHub-OTP
etag: "c9c3cea653b1e722852a41f65a43a5e969c0722c81525b3f1a27f7678269c6ba"
last-modified: Tue, 22 Feb 2022 15:07:13 GMT
x-oauth-scopes: public_repo, repo:status
x-accepted-oauth-scopes:
github-authentication-token-expiration: 2022-04-15 06:47:45 UTC
x-github-media-type: github.v3; format=json
x-ratelimit-limit: 5000
x-ratelimit-remaining: 4440
x-ratelimit-reset: 1647516784
x-ratelimit-used: 560
x-ratelimit-resource: core
access-control-expose-headers: ETag, Link, Location, Retry-After, X-GitHub-OTP, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Used, X-RateLimit-Resource, X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes, X-Poll-Interval, X-GitHub-Media-Type, X-GitHub-SSO, X-GitHub-Request-Id, Deprecation, Sunset
access-control-allow-origin: *
strict-transport-security: max-age=31536000; includeSubdomains; preload
x-frame-options: deny
x-content-type-options: nosniff
x-xss-protection: 0
referrer-policy: origin-when-cross-origin, strict-origin-when-cross-origin
content-security-policy: default-src 'none'
vary: Accept-Encoding, Accept, X-Requested-With
x-github-request-id: 4664:4A3B:121A47C:12EB215:623314EE
```

结果中的这几个参数最重要：

```sh
* x-ratelimit-limit: 是 5000 表明用户名和PAT是正确的，如果是 60 表明，这个用户名和token组合错误，为认证用户的限制是 60。
* x-ratelimit-remaining: 4440 当前这个小时里的剩余API请求数。
* x-ratelimit-reset: 1647516784 下一次访问限制被重置的时间。
```

在采集数据之前，确认能看到类似于以上的数据，否则不要继续做下面的步骤。

基于 GitHub API 使用的限流特性，建议分类，分时段采集数据，避免发生被限流的状况。

在使用 Filebeat 的 HTTP JSON 模块采集 GitHub API数据的过程中很难不会碰到被限流的情况（请求），在被限流的时候，可以在 filebeat 的滚动日志中看到类似下面的信息。

```sh
2022-03-17T11:22:53.262+0800	ERROR	[input.httpjson-stateless]	v2/input.go:115	Error while processing http request: failed to execute http client.Do: server responded with status code 403: {"message":"Resource protected by organization SAML enforcement. You must grant your Personal Access token access to this organization.","documentation_url":"https://docs.github.com/articles/authenticating-to-a-github-organization-with-saml-single-sign-on/"}	{"id": "BF2B0C218CAC3BA0", "input_url": "https://api.github.com/repos/elastic/beats/releases"}
```

以上信息表明，你当前的账户访问被限流了，你需要等一个小时后，在让 Filebeat 继续采集数据。

{{< panel status="success" title="自查点" >}}
你已经理解了 GitHub API 访问流控的基本知识。完成了在正式采集数据前的必要测试，已经确认当前用户名和PAT是正确无误。在浏览器中提前测试 filebeat.yml 配置文件中的 request.rul，确保所有 URL 都可以正常返回结果。 可选的测试：在操作系统上用clone的方式下载一个自己的项目，修改某个文件后，将更新push回去，确保和 GitHub 网站的服务是正常的。
{{< /panel >}}

下一步开始进行数据初始化前的准备基础准备工作。

### 采集并确认部分项目数据

在导入数据之前，需要完成下面这几项任务：

1. 导入为大家准备好的 Kibana 配置文件。
2. 在配置文件中只开启 overall 部分的数据采集
3. 首次启动 Filebeat ，并停止它
4. 在 Kibana 中确认采集到的数据
5. 为了大批量数据采集，修改索引字段数量上限

下面详细讲解操作过程。

在解压缩后的 zip 文件中，找到 export-v1.0.ndjson 文件；在浏览器中打开 Kibana 的界面，点击左侧菜单：需要导入示例 Kibana 可视化对象。文件在




## 定制项目数据分析看板


## 总结