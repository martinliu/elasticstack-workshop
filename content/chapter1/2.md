---
title: "使用 Kibana 分析开源项目的KPI"
date: 2017-10-17T15:26:15Z
draft: false
weight: 23
---

学习目标：

* 使用  zip / tar.gz 软件包在本地搭建 Elastic Stack 开发环境
* 使用 Filebeat 的 HTTP JSON inputedit 插件从 GitHub API 下载分析数据
* 在 Kibana 中查询和分析文档数据，为图形化展示做好准备
* 掌握 Kibana 数据分析展示看板的基本操作

## 准备工作

1. 在浏览器中打开网址 https://www.elastic.co/downloads/past-releases#elasticsearch ； 下载 elasticsearch-7.17.0-darwin-aarch64.tar.gz 、kibana-7.17.0-darwin-aarch64.tar.gz 、 filebeat-7.17.0-darwin-x86_64.tar.gz 软件包。请自行选择正确的平台，以上 darwin-aarch64 软件包适用于 moacOS M1 平台；而 darwin-x86_64 软件包适用于 macOS Intel 平台，它在 M1 上也可以正常运行。本视频演示的是下载 Windows 平台的 zip软件包
2. 在 GitHub 中创建 personal token，用于提升访问 GitHub Api 下载的数据条数限制

![github personal access token](/images/personal_access_token.png)

保存这个界面中的类似于这样的个人访问令牌 `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`


## 启动开发环境

下面是在 macOS M1 平台上解压缩 Elasticsearch 软件包，进入解压后的软件包的目录，使用其可执行文件启动服务。

```sh
tar zxvf elasticsearch-7.17.0-darwin-aarch64.tar.gz
cd elasticsearch-7.17.0
bin/elasticsearch -Enode.name=mac-m1
```

如果是在 Windows 平台上，使用系统带的解压缩软件将 zip 软件包解压。

```sh
tar zxvf kibana-7.17.0-darwin-aarch64.tar.gz
cd kibana-7.17.0-darwin-aarch64
bin/kibana
```

这样就启动了 Kibana 服务器，进入解压后的软件包的目录，使用其可执行文件启动服务。它默认会连接上一步所启动的 Elasticsearch 服务器，在这个开发环境中，默认没有启用用户名和密码认证。

解压缩 Filebeat 软件包，进入解压后的目录，备份默认的 `filebeat.yml` 重命名为 `filebeat.yml.bk`；使用微软的 Virtual Studio Code 编辑器创建一个新的名为 `filebeat.yml` 的空文件。

```sh
tar zxvf filebeat-7.17.0-darwin-x86_64.tar.gz
cd filebeat-7.17.0-darwin-x86_64
mv filebeat.yml filebeat.yml.bk
code filebeat.yml
```

为 Kibana 做初始化配置。点击左侧菜单，找到 Stack Management -- Kibana -- Advanced Setting 页面中的这两个选项。

* 打开 “Dark mode” 选项，打开暗黑模式界面。

![kibana-dark-mode](/images/kibana-dark-mode.png)

* 设置 “Document Explorer or classic view” 选项。关闭默认的 classic 经典视图模式。

![doc-explorer](/images/doc-explorer.png)

## Filebeat 同步数据

### 获取项目概要信息

本练习以 Kubernetes 项目为例。将下面分析 Kubernetes 项目的代码添加到空的 filebeat.yml 文件中。

```yml
# ============================== Filebeat inputs ===============================

filebeat.inputs:

# ------------------------- GitHub API - overview -------------------------
# https://docs.github.com/en/rest/reference/
# 
# overall         GET /repos/{owner}/{repo}
# contributors    GET /repos/{owner}/{repo}/contributors
# languages       GET /repos/{owner}/{repo}/languages
# tags            GET /repos/{owner}/{repo}/tags
# releases        GET /repos/{owner}/{repo}/releases
# issues          GET /repos/{owner}/{repo}/issues
# issues/comments GET /repos/{owner}/{repo}/issues/comments
# pulls           GET /repos/{owner}/{repo}/pulls
# pulls/comments  GET /repos/{owner}/{repo}/pulls/comments
# 
# 采集方法：
# 使用 Filebeat 的 httpjson 插件拉取api里的数据，
# 然后将json格式的数据转换成方便分析的 Elasticsearch 文档。


# # 获取 kubernetes 项目的概要信息 - overall
# # GET /repos/{owner}/{repo}
- type: httpjson
  interval: 5m
  config_version: 2
  request.url: https://api.github.com/repos/kubernetes/kubernetes
  request.method: GET 
  # 在请求中增加个人认证令牌，提高数据获取条数限制
  request.transforms:
    - set:
        target: header.Authorization
        value: 'token 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'
  # 使用数据处理器，修整数据
  processors:
    # 优化分析：增加方便搜索分析的字段  
    - add_fields: 
        fields:
          project: kubernetes
          kpi: overall
    # 解码裸json结果：将 message 字段中的 json 内容解码为多个字段
    - decode_json_fields: 
        fields: ["message"]
        target: "json"
    # 去重处理：根据 id 创建文档的唯一标识
    - fingerprint: 
        fields: ["json.id"]
        target_field: "@metadata._id"

# # 获取 kubernetes 项目的贡献者清单 - contributors
# # GET /repos/{owner}/{repo}/contributors 
- type: httpjson
  interval: 5m
  config_version: 2
  request.url: https://api.github.com/repos/kubernetes/kubernetes/contributors
  request.method: GET
  # 在请求中增加个人认证令牌，提高数据获取条数限制
  request.transforms:
    - set:
        target: header.Authorization
        value: 'token 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'
  # 滚动翻页：按照请求 url 中的页面大小向前翻页
  response.pagination: 
    - set: 
        target: url.params.page
        value: '[[add .last_response.page 1]]'
        fail_on_template: true     
  # 使用数据处理器修整数据
  processors:
    # 优化分析：增加方便搜索分析的字段  
    - add_fields: 
        fields:
          project: kubernetes
          kpi: contributors
    # 解码裸json结果：将 message 字段中的 json 内容解码为多个字段
    - decode_json_fields: 
        fields: ["message"]
        target: "json"
    # 去重处理：使用指纹处理器根据 id 创建文档的唯一标识
    - fingerprint: 
        fields: ["json.id"]
        target_field: "@metadata._id"

# # 获取 kubernetes 项目的各种编程语言的代码行数 - languages
# # GET /repos/{owner}/{repo}/languages 
- type: httpjson
  interval: 5m
  config_version: 2
  request.url: https://api.github.com/repos/kubernetes/kubernetes/languages
  request.method: GET 
  # 使用数据处理器，修整数据
  processors:
    # 优化分析：增加方便搜索分析的字段  
    - add_fields: 
        fields:
          project: kubernetes
          kpi: languages
    # 解码裸json结果：将 message 字段中的 json 内容解码为多个字段
    - decode_json_fields: 
        fields: ["message"]
        target: "json"

# # 获取 kubernetes 项目的标签清单 - tags  
# # GET /repos/{owner}/{repo}/tags  
- type: httpjson
  interval: 5m
  config_version: 2
  request.url: https://api.github.com/repos/kubernetes/kubernetes/tags
  request.method: GET
  # 滚动翻页：按照请求 url 中的页面大小向前翻页
  response.pagination: 
    - set: 
        target: url.params.page
        value: '[[add .last_response.page 1]]'
        fail_on_template: true   
  # 使用数据处理器，修整数据
  processors:
    # 优化分析：增加方便搜索分析的字段  
    - add_fields: 
        fields:
          project: kubernetes
          kpi: tags
    # 解码裸json结果：将 message 字段中的 json 内容解码为多个字段
    - decode_json_fields: 
        fields: ["message"]
        target: "json"
    # 去重处理：使用指纹处理器根据 id 创建文档的唯一标识
    - fingerprint: 
        fields: ["json.node_id"]
        target_field: "@metadata._id"

# 获取 kubernetes 项目的版本发布历史 - releases  
# GET /repos/{owner}/{repo}/releases
- type: httpjson
  interval: 5m
  config_version: 2
  request.url: https://api.github.com/repos/kubernetes/kubernetes/releases
  request.method: GET
  # 滚动翻页：按照请求 url 中的页面大小向前翻页
  response.pagination: 
    - set: 
        target: url.params.page
        value: '[[add .last_response.page 1]]'
        fail_on_template: true   
  # 使用数据处理器，修整数据
  processors:
    # 优化分析：增加方便搜索分析的字段  
    - add_fields: 
        fields:
          project: kubernetes
          kpi: releases
    # 解码裸json结果：将 message 字段中的 json 内容解码为多个字段
    - decode_json_fields: 
        fields: ["message"]
        target: "json"
    # 去重处理：使用指纹处理器根据 id 创建文档的唯一标识
    - fingerprint: 
        fields: ["json.id"]
        target_field: "@metadata._id"
    # 设置时间戳：用 create_at 字段作为文档的时间戳 
    - timestamp: 
        field: json.created_at
        layouts:
          - '2006-01-02T15:04:05Z'
          - '2006-01-02T15:04:05.999Z'
          - '2006-01-02T15:04:05.999-07:00'
        test:
          - '2019-06-22T16:33:51Z'
          - '2019-11-18T04:59:51.123Z'
          - '2020-08-03T07:10:20.123456+02:00'

# 获取 kubernetes 项目的所有 issue （oepn/closed）- issues 
# GET /repos/{owner}/{repo}/issues
- type: httpjson
  interval: 5m
  config_version: 2
  request.url: https://api.github.com/repos/kubernetes/kubernetes/issues?state=all
  request.method: GET
  # 在请求中增加个人认证令牌，提高数据获取条数限制
  request.transforms:
    - set:
        target: header.Authorization
        value: 'token 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'
  # 滚动翻页：按照请求 url 中的页面大小向前翻页
  response.pagination: 
    - set: 
        target: url.params.page
        value: '[[add .last_response.page 1]]'
        fail_on_template: true    
  # 使用数据处理器，修整数据
  processors:
    # 优化分析：增加方便搜索分析的字段  
    - add_fields: 
        fields:
          project: kubernetes
          kpi: issues
    # 解码裸json结果：将 message 字段中的 json 内容解码为多个字段
    - decode_json_fields: 
        fields: ["message"]
        target: "json"
    # 设置时间戳：用 create_at 字段作为文档的时间戳 
    - timestamp: 
        field: json.created_at
        layouts:
          - '2006-01-02T15:04:05Z'
          - '2006-01-02T15:04:05.999Z'
          - '2006-01-02T15:04:05.999-07:00'
        test:
          - '2019-06-22T16:33:51Z'
          - '2019-11-18T04:59:51.123Z'
          - '2020-08-03T07:10:20.123456+02:00'
    # 去重处理：使用指纹处理器根据 id 创建文档的唯一标识
    - fingerprint: 
        fields: ["json.id"]
        target_field: "@metadata._id"
    # 同步更新：更新已经摄入的数据内容
    - script:  
        lang: javascript
        id: update_instead_of_ignore_same_id
        source: >
          function process(event) {
            event.Put("@metadata.op_type", "index")
          }  

# 获取 kubernetes 项目的所有 pull request （open/closed） - pulls 
# GET /repos/{owner}/{repo}/pulls
- type: httpjson
  interval: 5m
  config_version: 2
  request.url: https://api.github.com/repos/kubernetes/kubernetes/pulls?state=all
  request.method: GET
  # 在请求中增加个人认证令牌，提高数据获取条数限制
  request.transforms:
    - set:
        target: header.Authorization
        value: 'token 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'
  # 滚动翻页：按照请求 url 中的页面大小向前翻页
  response.pagination: 
    - set: 
        target: url.params.page
        value: '[[add .last_response.page 1]]'
        fail_on_template: true    
  # 使用数据处理器，修整数据
  processors:
    # 优化分析：增加方便搜索分析的字段  
    - add_fields: 
        fields:
          project: kubernetes
          kpi: pulls
    # 解码裸json结果：将 message 字段中的 json 内容解码为多个字段
    - decode_json_fields: 
        fields: ["message"]
        target: "json"
    # 设置时间戳：用 create_at 字段作为文档的时间戳 
    - timestamp: 
        field: json.created_at
        layouts:
          - '2006-01-02T15:04:05Z'
          - '2006-01-02T15:04:05.999Z'
          - '2006-01-02T15:04:05.999-07:00'
        test:
          - '2019-06-22T16:33:51Z'
          - '2019-11-18T04:59:51.123Z'
          - '2020-08-03T07:10:20.123456+02:00'
    # 去重处理：使用指纹处理器根据 id 创建文档的唯一标识
    - fingerprint: 
        fields: ["json.id"]
        target_field: "@metadata._id"
    # 同步更新：更新已经摄入的数据内容
    - script:  
        lang: javascript
        id: update_instead_of_ignore_same_id
        source: >
          function process(event) {
            event.Put("@metadata.op_type", "index")
          }  


# ---------------------------- Elasticsearch Output ----------------------------
output.elasticsearch:
  # Array of hosts to connect to.
  hosts: ["localhost:9200"]

# ================================== Logging ===================================
# logging.level: debug

# ================================= Processors =================================
# 删除 Filebeeat 采集到的无关数据，节省本地存储空间
processors:
 - drop_fields:
     fields: ["ecs", "agent", "log", "input", "host", "message"]          
```


## 创建数据分析看板


## 总结